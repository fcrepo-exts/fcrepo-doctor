/*
 * The contents of this file are subject to the license and copyright
 * detailed in the LICENSE and NOTICE files at the root of the source
 * tree.
 */

package org.fcrepo.doctor.cli;

import ch.qos.logback.classic.Level;
import ch.qos.logback.classic.LoggerContext;
import ch.qos.logback.classic.encoder.PatternLayoutEncoder;
import ch.qos.logback.classic.spi.ILoggingEvent;
import ch.qos.logback.core.ConsoleAppender;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;
import com.github.benmanes.caffeine.cache.Caffeine;
import edu.wisc.library.ocfl.api.MutableOcflRepository;
import edu.wisc.library.ocfl.aws.OcflS3Client;
import edu.wisc.library.ocfl.core.OcflRepositoryBuilder;
import edu.wisc.library.ocfl.core.path.mapper.LogicalPathMappers;
import edu.wisc.library.ocfl.core.storage.OcflStorage;
import edu.wisc.library.ocfl.core.storage.OcflStorageBuilder;
import org.apache.commons.lang3.StringUtils;
import org.apache.commons.lang3.SystemUtils;
import org.fcrepo.doctor.analyzer.ObjectAnalyzer;
import org.fcrepo.doctor.analyzer.RepoAnalyzer;
import org.fcrepo.doctor.analyzer.reader.CachedContentReaderFactory;
import org.fcrepo.doctor.analyzer.reader.ContentReaderFactory;
import org.fcrepo.doctor.analyzer.reader.DefaultContentReaderFactory;
import org.fcrepo.doctor.fixer.ObjectFixer;
import org.fcrepo.doctor.fixer.RepoFixer;
import org.fcrepo.doctor.problem.ProblemType;
import org.fcrepo.doctor.problem.detector.BinaryDescSubjectProblemDetector;
import org.fcrepo.doctor.problem.detector.ChainedProblemDetector;
import org.fcrepo.doctor.problem.fixer.BinaryDescSubjectProblemFixer;
import org.fcrepo.doctor.problem.fixer.ProblemFixer;
import org.fcrepo.doctor.problem.reader.DefaultProblemReader;
import org.fcrepo.doctor.problem.writer.FileProblemWriter;
import org.fcrepo.doctor.problem.writer.ProblemWriter;
import org.fcrepo.doctor.problem.writer.StatsProblemWriter;
import org.fcrepo.storage.ocfl.CommitType;
import org.fcrepo.storage.ocfl.DefaultOcflObjectSessionFactory;
import org.fcrepo.storage.ocfl.OcflObjectSessionFactory;
import org.fcrepo.storage.ocfl.cache.CaffeineCache;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import picocli.CommandLine;
import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;
import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;
import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;
import software.amazon.awssdk.regions.Region;
import software.amazon.awssdk.services.s3.S3Client;

import java.io.FileNotFoundException;
import java.net.URI;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.time.Duration;
import java.util.List;
import java.util.Map;
import java.util.concurrent.Callable;

import static com.fasterxml.jackson.databind.SerializationFeature.WRITE_DATES_AS_TIMESTAMPS;

/**
 * Main application command
 *
 * @author winckles
 */
@CommandLine.Command(name = "fcrepo-doctor",
        version = "0.0.1-SNAPSHOT",
        mixinStandardHelpOptions = true,
        description = "A tool for diagnosing and repairing OCFL-based Fedora repositories.")
public class DoctorCmd implements Callable<Integer> {

    private static final Logger LOG = LoggerFactory.getLogger(DoctorCmd.class);

    private static final String FILE_PREFIX = "fcrepo-doctor-";
    private static final String PROBLEMS_OUTPUT = FILE_PREFIX + "problems.json";
    private static final String FAILED_OUTPUT = FILE_PREFIX + "failed-problems.json";
    private static final String INCOMPLETE_OUTPUT = FILE_PREFIX + "incomplete-problems.json";

    private static final String USER_NAME = "fedoraAdmin";
    private static final String USER_URI = "info:fedora/fedoraAdmin";
    private static final String VERSION_MESSAGE = "Generated by fcrepo-doctor";

    @CommandLine.Option(names = {"-r", "--ocfl-root"},
            required = true,
            description = "Path to Fedora's OCFL storage root. When using S3, this is the prefix within the bucket" +
                    " that the storage root is located it, and it should be an empty string if no prefix is used.")
    private String ocflRoot;

    @CommandLine.Option(names = {"-t", "--temp"},
            required = true,
            description = "Path to a directory on the same filesystem as the OCFL root to use for temporary files")
    private Path tempDir;

    @CommandLine.Option(names = {"-o", "--output"},
            defaultValue = ".",
            description = "Path to a directory to write output files into. Default: current directory")
    private Path outputDir;

    @CommandLine.Option(names = {"-f", "--fix"},
            description = "Path to a file that contains a list of files to fix." +
                    " This file is generated by first running the command without this option.")
    private Path problemsFile;

    @CommandLine.Option(names = {"--disable-auto-versioning"},
            description = "Disables auto-versioning, which means that applying fixes will NOT automatically" +
                    " result in a new version of the affected resources.")
    private boolean disableAutoVersioning;

    @CommandLine.Option(names = {"-p", "--parallelism"},
            defaultValue = "0",
            showDefaultValue = CommandLine.Help.Visibility.NEVER,
            description = "Number of threads to use. Default: number of cores minus one")
    private int parallelism;

    @CommandLine.Option(names = {"--s3-profile"},
            description = "S3 profile to use.")
    private String s3Profile;

    @CommandLine.Option(names = {"--s3-access-key"},
            description = "S3 access key. If provided, a secret key must also be specified")
    private String s3AccessKey;

    @CommandLine.Option(names = {"--s3-secret-key"},
            description = "S3 secret key. If provided, an access key must also be specified")
    private String s3SecretKey;

    @CommandLine.Option(names = {"--s3-region"},
            description = "S3 region")
    private String s3Region;

    @CommandLine.Option(names = {"--s3-endpoint"},
            description = "URL to the S3 endpoint")
    private String s3Endpoint;

    @CommandLine.Option(names = {"--s3-bucket"},
            description = "S3 bucket the OCFL repository is in")
    private String s3Bucket;

    @CommandLine.Option(names = {"-v", "--verbose"},
            defaultValue = "false",
            description = "Enable more verbose logging")
    private boolean verbose;

    @CommandLine.Option(names = {"-d", "--debug"},
            defaultValue = "false",
            description = "Enable stack traces")
    private boolean debug;

    @Override
    public Integer call() {
        configureLogging();

        try {
            Files.createDirectories(tempDir);

            final var ocflRepo = createOcflRepo();
            final var objectSessionFactory = createObjectSessionFactory(ocflRepo);

            if (problemsFile == null) {
                analyze(ocflRepo, objectSessionFactory);
            } else {
                if (Files.notExists(problemsFile)) {
                    throw new FileNotFoundException("File not found: " + problemsFile.toString());
                }
                fix(objectSessionFactory);
            }
        } catch (Exception e) {
            LOG.error("Execution failed: {}", e.getMessage(), e);
            return 1;
        }

        return 0;
    }

    private void analyze(final MutableOcflRepository ocflRepo,
                         final OcflObjectSessionFactory objectSessionFactory) throws Exception {
        final var problemDetector = new ChainedProblemDetector(List.of(
                new BinaryDescSubjectProblemDetector()
        ));
        final var objectAnalyzer = new ObjectAnalyzer(objectSessionFactory,
                problemDetector,
                createContentReaderFactory());

        try (final var problemWriter =
                     new StatsProblemWriter(createProblemWriter(PROBLEMS_OUTPUT, new ObjectMapper()))) {
            final var repoAnalyzer = new RepoAnalyzer(getParallelism(), ocflRepo, objectAnalyzer, problemWriter);
            repoAnalyzer.analyze();
        }
    }

    private void fix(final OcflObjectSessionFactory objectSessionFactory) throws Exception {
        final Map<ProblemType, ProblemFixer> problemFixers = Map.of(
                ProblemType.INVALID_BIN_DESC_SUBJ, new BinaryDescSubjectProblemFixer()
        );
        final var objectFixer = new ObjectFixer(objectSessionFactory, problemFixers);

        final var objectMapper = new ObjectMapper();

        // Must read problems first to avoid overwriting a fcrepo-doctor-incomplete-problems.json file
        final var problemReader = new DefaultProblemReader(objectMapper);
        final var problems = problemReader.read(problemsFile);

        try (final var failedWriter = createProblemWriter(FAILED_OUTPUT, objectMapper);
             final var incompleteWriter = createProblemWriter(INCOMPLETE_OUTPUT, objectMapper)) {
            final var repoFixer = new RepoFixer(getParallelism(),
                    objectFixer,
                    failedWriter,
                    incompleteWriter);
            repoFixer.fixProblems(problems);
        }
    }

    private void configureLogging() {
        final var context = (LoggerContext) LoggerFactory.getILoggerFactory();
        final var logger = context.getLogger("org.fcrepo.doctor");
        if (verbose) {
            logger.setLevel(Level.DEBUG);
        }
        if (debug) {
            final var appender = (ConsoleAppender<ILoggingEvent>) logger.getAppender("STDOUT");
            appender.stop();
            final var encoder = (PatternLayoutEncoder) appender.getEncoder();
            encoder.stop();
            encoder.setPattern(encoder.getPattern().replace("nopex", "ex"));
            encoder.start();
            appender.start();
        }
    }

    private MutableOcflRepository createOcflRepo() {
        final var logicalPathMapper = SystemUtils.IS_OS_WINDOWS ?
                LogicalPathMappers.percentEncodingWindowsMapper() : LogicalPathMappers.percentEncodingLinuxMapper();

        return new OcflRepositoryBuilder()
                .logicalPathMapper(logicalPathMapper)
                .storage(createOcflStorage())
                .workDir(tempDir)
                .buildMutable();
    }

    private OcflStorage createOcflStorage() {
        if (hasS3Config()) {
            return createS3OcflStorage();
        } else {
            return createFsOcflStorage();
        }
    }

    private OcflStorage createFsOcflStorage() {
        return OcflStorageBuilder.builder().fileSystem(Paths.get(ocflRoot)).build();
    }

    private OcflStorage createS3OcflStorage() {
        return OcflStorageBuilder.builder()
                .cloud(OcflS3Client.builder()
                        .s3Client(createS3Client())
                        .bucket(s3Bucket)
                        .repoPrefix(ocflRoot)
                        .build())
                .build();
    }

    private OcflObjectSessionFactory createObjectSessionFactory(final MutableOcflRepository ocflRepo) {
        final var objectMapper = new ObjectMapper()
                .configure(WRITE_DATES_AS_TIMESTAMPS, false)
                .registerModule(new JavaTimeModule())
                .setSerializationInclusion(JsonInclude.Include.NON_NULL);

        final var headersCache = Caffeine.newBuilder()
                .maximumSize(512)
                .expireAfterAccess(Duration.ofMinutes(10))
                .build();

        final var rootIdCache = Caffeine.newBuilder()
                .maximumSize(512)
                .expireAfterAccess(Duration.ofMinutes(10))
                .build();

        return new DefaultOcflObjectSessionFactory(ocflRepo,
                tempDir,
                objectMapper,
                new CaffeineCache<>(headersCache),
                new CaffeineCache<>(rootIdCache),
                disableAutoVersioning ? CommitType.UNVERSIONED : CommitType.NEW_VERSION,
                VERSION_MESSAGE,
                USER_NAME,
                USER_URI);
    }

    private ProblemWriter createProblemWriter(final String filename,
                                              final ObjectMapper objectMapper) {
        return new FileProblemWriter(objectMapper, outputDir.resolve(filename));
    }

    private ContentReaderFactory createContentReaderFactory() {
        if (hasS3Config()) {
            return new CachedContentReaderFactory(tempDir);
        } else {
            return new DefaultContentReaderFactory();
        }
    }

    private S3Client createS3Client() {
        final var builder = S3Client.builder();

        // This is often required for non-AWS S3 implementations
        builder.serviceConfiguration(config -> config.pathStyleAccessEnabled(true));

        if (StringUtils.isNotBlank(s3Region)) {
            builder.region(Region.of(s3Region));
        }

        if (StringUtils.isNotBlank(s3Endpoint)) {
            builder.endpointOverride(URI.create(s3Endpoint));
        }

        if (StringUtils.isNotBlank(s3Profile)) {
            builder.credentialsProvider(ProfileCredentialsProvider.create(s3Profile));
        }

        if (StringUtils.isNoneBlank(s3AccessKey, s3SecretKey)) {
            builder.credentialsProvider(StaticCredentialsProvider.create(
                    AwsBasicCredentials.create(s3AccessKey, s3SecretKey)));
        }

        return builder.build();
    }

    private int getParallelism() {
        return parallelism > 0 ? parallelism : Runtime.getRuntime().availableProcessors() - 1;
    }

    private boolean hasS3Config() {
        return StringUtils.isNotBlank(s3AccessKey)
                || StringUtils.isNotBlank(s3SecretKey)
                || StringUtils.isNotBlank(s3Profile)
                || StringUtils.isNotBlank(s3Endpoint)
                || StringUtils.isNotBlank(s3Bucket)
                || StringUtils.isNotBlank(s3Region);
    }

}
